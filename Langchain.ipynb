{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOxcWjZ8EYJutfYuYcakHz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Perfect-Cube/Volkswagon-imobilothon-4.0/blob/main/Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50gFslw8qbEP",
        "outputId": "8d188227-327d-4f85-d058-2f205373a529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/412.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GROQ_API_KEY\"):\n",
        "  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "model = ChatGroq(model=\"llama3-8b-8192\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aThw0Abmqk-Y",
        "outputId": "b2b09d0f-148a-446a-ed03-beaa04a067ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for Groq: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"learning to gen ai, llm, langchain\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Weko3Q__qtxN",
        "outputId": "8a8fc266-fd2d-4ac4-b4b3-77dc22622be4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Learning to generate AI, LLM (Large Language Model), and LangChain! That's a fascinating topic. Here's a beginner's guide to get you started:\\n\\n**What are Large Language Models (LLMs)?**\\n\\nLarge Language Models (LLMs) are artificial intelligence models that are trained on massive amounts of text data to generate human-like language. They're designed to understand and generate text, and are often used for natural language processing (NLP) tasks such as language translation, text summarization, and chatbots.\\n\\n**Key Components of LLMs:**\\n\\n1. **Tokenization**: breaking down text into individual words or tokens.\\n2. **Embeddings**: representing each token as a numerical vector (embedding) to capture its meaning.\\n3. **Encoder-Decoder Architecture**: the core component of LLMs, which consists of an encoder that processes input text and a decoder that generates output text.\\n\\n**Types of LLMs:**\\n\\n1. **Transformer-based LLMs**: popular architectures like BERT, RoBERTa, and XLNet, which use self-attention mechanisms to process input text.\\n2. **Recurrence-based LLMs**: older architectures like Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, which use recurrent connections to process input text.\\n\\n**How to Learn LLMs:**\\n\\n1. **Read the basics**: Start with introductory resources like Wikipedia, tutorials, and blog posts.\\n2. **Math and programming**: Familiarize yourself with linear algebra, calculus, and programming languages like Python, TensorFlow, or PyTorch.\\n3. **Choose a framework**: Pick a popular framework like Hugging Face Transformers, PyTorch, or TensorFlow, and learn its basics.\\n4. **Practice with tutorials**: Follow tutorials and exercises on platforms like Kaggle, GitHub, or Coursera.\\n5. **Join online communities**: Participate in online forums like Reddit's r/MachineLearning and r/NLP, and engage with professionals and enthusiasts.\\n\\n**LangChain:**\\n\\nLangChain is a type of LLM that focuses on generating human-like language. It's a specific application of LLMs, which can be used for various tasks such as:\\n\\n1. **Text summarization**: summarizing long pieces of text into shorter summaries.\\n2. **Chatbots**: generating responses to user input.\\n3. **Language translation**: translating text from one language to another.\\n4. **Content generation**: generating articles, stories, or other written content.\\n\\n**Resources to Get You Started:**\\n\\n1. **Hugging Face Transformers**: A popular framework for LLMs, with tutorials and examples.\\n2. **PyTorch**: A popular deep learning framework, with tutorials and examples.\\n3. **TensorFlow**: Another popular deep learning framework, with tutorials and examples.\\n4. **Kaggle**: A platform for machine learning competitions and tutorials.\\n5. **Coursera**: An online learning platform with courses on machine learning and NLP.\\n6. **Reddit's r/MachineLearning and r/NLP**: Online communities for machine learning and NLP enthusiasts.\\n\\nRemember, learning LLMs and LangChain requires dedication, persistence, and practice. Start with the basics, and gradually move on to more advanced topics. Good luck!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 670, 'prompt_tokens': 20, 'total_tokens': 690, 'completion_time': 0.558333333, 'prompt_time': 0.004110263, 'queue_time': 0.114536677, 'total_time': 0.562443596}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None}, id='run-41ac59cc-ba28-4235-933f-7a906572c77c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 670, 'total_tokens': 690})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}